
    PART ONE: ROOT FILES
            This is the chessism-api project, is a suite for chess analysis,
            it's source is mainly the chess.com players and games.
            
        


### main.py 
#main.py
import os
from fastapi import FastAPI
from contextlib import asynccontextmanager
import constants

# --- MODIFIED: Import the fens and new analysis router ---
from chessism_api.routers import players, games, fens, analysis

# --- NEW: Import the init_db function ---
from chessism_api.database.engine import init_db
# --- NEW: Import Redis functions ---
from chessism_api.redis_client import get_redis_pool, close_redis_pool

CONN_STRING = constants.CONN_STRING

# lifespan event handler
@asynccontextmanager
async def lifespan(app: FastAPI):
    # --- Database Setup ---
    if not CONN_STRING:
        raise ValueError("DATABASE_URL environment variable is not set.")
    await init_db(CONN_STRING)
    
    # --- NEW: Redis Setup ---
    # Initialize the pool on startup
    await get_redis_pool()
    
    print(f"BASAL CHESSISM Server ON YO!... (DB: {CONN_STRING.split('@')[-1]})")
    yield
    
    # --- NEW: Redis Shutdown ---
    await close_redis_pool()
    print('BASAL CHESSISM Server DOWN YO!...')

app = FastAPI(lifespan=lifespan)

@app.get("/")
def read_root():
    return "BASAL CHESSISM server running."

# --- NEW: Include the router ---
# This makes the endpoint available at /players/current_players
app.include_router(players.router, prefix="/players", tags=["Players"])

# --- NEW: Include the games router ---
app.include_router(games.router, prefix="/games", tags=["Games"])

# --- NEW: Include the FENs router ---
app.include_router(fens.router, prefix="/fens", tags=["FENs"])

# --- NEW: Include the Analysis router ---
app.include_router(analysis.router, prefix="/analysis", tags=["Analysis"])



### Dockerfile 
# This is the NEW Dockerfile for your main API (in the root directory)
# It's a simple Python server.

FROM python:3.10-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy the application code
COPY main.py .
COPY constants.py .

# --- THIS IS THE FIX ---
# We must also copy the worker.py file into the image
# so the worker containers can find it.
COPY worker.py .

# --- NEW: Copy the new API directory ---
COPY chessism_api/ ./chessism_api

# Expose the port the app runs on
EXPOSE 8000

# Run the Uvicorn server (This is the default CMD, which the workers override)
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]



### docker-compose.yml 
services:
  chessism-api:
    build: .
    image: chessism-api:latest
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://chessism_user:chessism_pass@db:5432/chessism_db
      - REDIS_HOST=redis
    networks:
      - chessism_net
    depends_on:
      db:
        condition: service_healthy
      leela-service-gpu0:
        condition: service_started
      leela-service-gpu1:
        condition: service_started
      redis:
        condition: service_healthy
    volumes:
      - ./api_logs:/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  leela-service-gpu0:
    build: ./leela-service
    image: leela-service-gpu0
    ports:
      - "9999:9999"
    environment:
      - LC0_TARGET_GPU=0
      - LC0_BACKEND=cuda-fp16
      - CUDA_VISIBLE_DEVICES=0
    networks:
      - chessism_net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: all

  leela-service-gpu1:
    build: ./leela-service
    image: leela-service-gpu1
    ports:
      - "9998:9999"
    environment:
      - LC0_TARGET_GPU=0
      - LC0_BACKEND=cuda
      - CUDA_VISIBLE_DEVICES=1
    networks:
      - chessism_net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: all

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: chessism_user
      POSTGRES_PASSWORD: chessism_pass
      POSTGRES_DB: chessism_db
    ports:
      - "5433:5432"
    volumes:
      - ./db_data:/var/lib/postgresql/data
    networks:
      - chessism_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U chessism_user -d chessism_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - chessism_net
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  worker-gpu0:
    build: .
    image: chessism-api:latest 
    container_name: worker-gpu0
    command: arq worker.WorkerSettings
    environment:
      - DATABASE_URL=postgresql+asyncpg://chessism_user:chessism_pass@db:5432/chessism_db
      - REDIS_HOST=redis
      - QUEUE_NAME=gpu_0_queue
    networks:
      - chessism_net
    depends_on:
      redis:
        condition: service_healthy
      db:
        condition: service_healthy
      leela-service-gpu0:
        condition: service_started
      leela-service-gpu1:
        condition: service_started
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  worker-gpu1:
    build: .
    image: chessism-api:latest 
    container_name: worker-gpu1
    command: arq worker.WorkerSettings
    environment:
      - DATABASE_URL=postgresql+asyncpg://chessism_user:chessism_pass@db:5432/chessism_db
      - REDIS_HOST=redis
      - QUEUE_NAME=gpu_1_queue
    networks:
      - chessism_net
    depends_on:
      redis:
        condition: service_healthy
      db:
        condition: service_healthy
      leela-service-gpu0:
        condition: service_started
      leela-service-gpu1:
        condition: service_started
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  fen-worker-1:
    build: .
    image: chessism-api:latest
    container_name: fen-worker-1
    command: arq worker.WorkerSettings
    environment:
      - DATABASE_URL=postgresql+asyncpg://chessism_user:chessism_pass@db:5432/chessism_db
      - REDIS_HOST=redis
      - QUEUE_NAME=fen_queue
    networks:
      - chessism_net
    depends_on:
      - redis
      - db

  fen-worker-2:
    build: .
    image: chessism-api:latest
    container_name: fen-worker-2
    command: arq worker.WorkerSettings
    environment:
      - DATABASE_URL=postgresql+asyncpg://chessism_user:chessism_pass@db:5432/chessism_db
      - REDIS_HOST=redis
      - QUEUE_NAME=fen_queue
    networks:
      - chessism_net
    depends_on:
      - redis
      - db

  fen-worker-3:
    build: .
    image: chessism-api:latest
    container_name: fen-worker-3
    command: arq worker.WorkerSettings
    environment:
      - DATABASE_URL=postgresql+asyncpg://chessism_user:chessism_pass@db:5432/chessism_db
      - REDIS_HOST=redis
      - QUEUE_NAME=fen_queue
    networks:
      - chessism_net
    depends_on:
      - redis
      - db

  # --- NEW: THE "BOSS" WORKER ---
  pipeline-worker:
    build: .
    image: chessism-api:latest
    container_name: pipeline-worker
    command: arq worker.WorkerSettings
    environment:
      - DATABASE_URL=postgresql+asyncpg://chessism_user:chessism_pass@db:5432/chessism_db
      - REDIS_HOST=redis
      - QUEUE_NAME=pipeline_queue # <-- Listens to its own queue
    networks:
      - chessism_net
    depends_on:
      - redis
      - db

networks:
  chessism_net:
    driver: bridge

volumes:
  redis_data:
  db_data:



### constants.py 
import os

CONN_STRING = os.environ.get("DATABASE_URL")

if not CONN_STRING:
    raise ValueError("DATABASE_URL environment variable is not set.")

# --- Game Results Constants ---
DRAW_RESULTS = ['50move', 'agreed', 'insufficient', 'repetition', 'stalemate', 'timevsinsufficient']
LOSE_RESULTS = ['checkmated', 'resigned', 'threecheck', 'timeout', 'abandoned']
WINING_RESULT = ['win', 'kingofthehill']

# --- Other Constants ---
USER_AGENT = "ChessismApp/1.0 (marinlafare@gmail.com)"
LEADERBOARD = "https://api.chess.com/pub/leaderboards"
STATS = "https://api.chess.com/pub/player/{username}/stats"
PLAYER="https://api.chess.com/pub/player/{player}"
DOWNLOAD_MONTH = "https://api.chess.com/pub/player/{player}/games/{year}/{month}"


#USER_AGENT="Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0"




### requirements.txt 
fastapi
uvicorn
python-dotenv
sqlalchemy
asyncpg
pydantic
httpx
requests
python-chess
arq[redis]



### testing_chessism.py 
import httpx
import asyncio
import os
from pprint import pprint

# All API calls go to the chessism-api service
API_BASE_URL = "http://localhost:8000"

async def test_api_create_games(player_name: str):
    """
    Calls the POST /games endpoint to trigger the full
    download and ingestion process for a player.
    """
    print("\n--- [API TEST] ---")
    print(f"Starting 'Create Games' job for player: {player_name}")
    print("This may take a very long time, as it is downloading")
    print("all game archives one-by-one...")
    
    url = f"{API_BASE_URL}/games" # Correct path
    payload = {"player_name": player_name}
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            # Set timeout=None because this can take minutes
            response = await client.post(url, json=payload, timeout=None)
        
        response.raise_for_status() # Raise an error for 4xx or 5xx status
        
        print("\n--- SUCCESS (Job Response) ---")
        pprint(response.json())
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except httpx.RequestError as e:
        print(f"\n--- REQUEST ERROR (Connection Failed) ---")
        print(repr(e))
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))


async def test_api_get_game(link: int):
    """
    Calls the GET /games/{link} endpoint to fetch a single game.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Fetching game link: {link}")
    
    url = f"{API_BASE_URL}/games/{link}"
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.get(url)
        
        response.raise_for_status()
        
        print("\n--- SUCCESS (Game Data) ---")
        pprint(response.json())
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))


async def test_api_get_players():
    """
    Calls the GET /players/current_players endpoint.
    """
    print(f"\n--- [API TEST] ---")
    print("Fetching all 'real' players (joined != 0)...")
    
    url = f"{API_BASE_URL}/players/current_players"
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.get(url)
        
        response.raise_for_status()
        
        print("\n--- SUCCESS (Player List) ---")
        pprint(response.json())
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))

async def test_api_get_player_profile(player_name: str):
    """
    Calls the GET /players/{player_name} endpoint.
    This will fetch from DB or from Chess.com if not found.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Fetching API profile for: {player_name}")
    
    url = f"{API_BASE_URL}/players/{player_name}"
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.get(url)
        
        response.raise_for_status()
        
        print("\n--- SUCCESS (Profile Data from API) ---")
        pprint(response.json())
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))
async def test_api_get_player_stats(player_name: str):
    """
    Calls the GET /players/{player_name}/stats endpoint.
    This will fetch fresh stats from Chess.com and "upsert" them.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Fetching API stats for: {player_name}")
    
    url = f"{API_BASE_URL}/players/{player_name}/stats"
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.get(url)
        
        response.raise_for_status()
        
        print("\n--- SUCCESS (Stats Data from API) ---")
        pprint(response.json())
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except httpx.RequestError as e:
        print(f"\n--- REQUEST ERROR (Connection Failed) ---")
        print(repr(e))
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))

async def test_api_update_all_stats():
    """
    Calls the POST /players/update-all-stats endpoint.
    This triggers a background task on the server.
    """
    print(f"\n--- [API TEST] ---")
    print("Triggering batch job to update stats for ALL primary players...")
    
    url = f"{API_BASE_URL}/players/update-all-stats"
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            # This request should be very fast, so a short timeout is fine
            response = await client.post(url, timeout=30) 
        
        response.raise_for_status()
        
        print("\n--- SUCCESS (Job Started) ---")
        print(f"Status Code: {response.status_code}") # Should be 202
        pprint(response.json())
        print("\nCheck your docker-compose logs to see the job progress.")
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except httpx.RequestError as e:
        print(f"\n--- REQUEST ERROR (Connection Failed) ---")
        print(repr(e))
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))
async def test_api_generate_fens(total_games: int, batch_size: int = 10):
    """
    Calls the POST /fens/generate endpoint.
    This triggers a background task on the server.
    
    Args:
        total_games (int): The max number of games to process.
        batch_size (int): How many games to process per loop.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Triggering batch job to generate FENs for {total_games} games...")
    
    url = f"{API_BASE_URL}/fens/generate"
    
    payload = {
        "total_games_to_process": total_games,
        "batch_size": batch_size
    }
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.post(url, json=payload, timeout=30) 
        
        response.raise_for_status()
        
        print("\n--- SUCCESS (Job Started) ---")
        print(f"Status Code: {response.status_code}") # Should be 202
        pprint(response.json())
        print("\nCheck your docker-compose logs to see the job progress.")
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except httpx.RequestError as e:
        print(f"\n--- REQUEST ERROR (Connection Failed) ---")
        print(repr(e))
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))
async def test_api_get_top_fens(limit: int = 20):
    """
    Calls the GET /fens/top endpoint with a query parameter.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Fetching top {limit} FENs...")
    
    # --- FIXED URL: Changed from /fens/top/{limit} to /fens/top?limit={limit} ---
    url = f"{API_BASE_URL}/fens/top?limit={limit}"
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.get(url, timeout=30) 
        
        response.raise_for_status()
        
        data = response.json()
        
        print("\n--- SUCCESS (Top FENs) ---")
        # Print the results string directly for clear output
        if 'results' in data:
            print(data['results'])
        else:
            pprint(data)
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except httpx.RequestError as e:
        print(f"\n--- REQUEST ERROR (Connection Failed) ---")
        print(repr(e))
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))
async def test_api_get_sum_n_games(threshold: int = 10):
    """
    Calls the GET /fens/sum_n_games endpoint.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Fetching SUM(n_games) for FENs where n_games > {threshold}...")
    
    url = f"{API_BASE_URL}/fens/sum_n_games?threshold={threshold}"
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.get(url, timeout=60) # Give it a reasonable timeout
        
        response.raise_for_status()
        
        data = response.json()
        
        print("\n--- SUCCESS (Sum Data) ---")
        pprint(data)
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except httpx.RequestError as e:
        print(f"\n--- REQUEST ERROR (Connection Failed) ---")
        print(repr(e))
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))
        
async def test_api_run_analysis_job(
    gpu_index: int, 
    total_fens: int, 
    batch_size: int, 
    nodes: int
):
    """
    Calls the POST /analysis/run_job endpoint.
    This triggers a background task on the server.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Triggering analysis job on GPU {gpu_index} for {total_fens} FENs...")
    
    url = f"{API_BASE_URL}/analysis/run_job"
    
    payload = {
        "gpu_index": gpu_index,
        "total_fens_to_process": total_fens,
        "batch_size": batch_size,
        "nodes_limit": nodes
    }
    
    try:
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.post(url, json=payload, timeout=30) 
        
        response.raise_for_status()
        
        print("\n--- SUCCESS (Job Started) ---")
        print(f"Status Code: {response.status_code}") # Should be 202
        pprint(response.json())
        print("\nCheck your docker-compose logs to see the job progress.")
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except httpx.RequestError as e:
        print(f"\n--- REQUEST ERROR (Connection Failed) ---")
        print(repr(e))
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))

async def test_api_run_player_analysis_job(
    player_name: str,
    gpu_index: int, 
    total_fens: int, 
    batch_size: int, 
    nodes: int
):
    """
    Calls the POST /analysis/run_player_job endpoint.
    This triggers a background task on the server.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Triggering PLAYER job for '{player_name}' on GPU {gpu_index}...")
    
    url = f"{API_BASE_URL}/analysis/run_player_job"
    
    payload = {
        "player_name": player_name,
        "gpu_index": gpu_index,
        "total_fens_to_process": total_fens,
        "batch_size": batch_size,
        "nodes_limit": nodes
    }
    
    try:
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.post(url, json=payload, timeout=30) 
        
        response.raise_for_status()
        
        print("\n--- SUCCESS (Player Job Started) ---")
        print(f"Status Code: {response.status_code}") # Should be 202
        pprint(response.json())
        print("\nCheck your docker-compose logs to see the job progress.")
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except httpx.RequestError as e:
        print(f"\n--- REQUEST ERROR (Connection Failed) ---")
        print(repr(e))
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))
async def test_api_get_top_fens_unscored(limit: int = 20):
    """
    Calls the GET /fens/top_unscored endpoint with a query parameter.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Fetching top {limit} UNSCORED FENs...")
    
    url = f"{API_BASE_URL}/fens/top_unscored?limit={limit}"
    
    try:
        # --- FIX: Disable HTTP/2, force HTTP/1.1 ---
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.get(url, timeout=30) 
        
        response.raise_for_status()
        
        data = response.json()
        
        print("\n--- SUCCESS (Top Unscored FENs) ---")
        if 'results' in data:
            print(data['results'])
        else:
            pprint(data)
        
    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        try:
            pprint(e.response.json())
        except:
            print(e.response.text)
    except httpx.RequestError as e:
        print(f"\n--- REQUEST ERROR (Connection Failed) ---")
        print(repr(e))
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))
async def test_api_get_fen_score_counts(player_name: str):
    """
    Calls the GET /players/{player_name}/fen_counts endpoint.
    Returns the number of FENs where score is 0 vs not 0.
    """
    print(f"\n--- [API TEST] ---")
    print(f"Fetching FEN score counts for: {player_name}")
    
    url = f"{API_BASE_URL}/players/{player_name}/fen_counts"
    
    try:
        async with httpx.AsyncClient(http2=False) as client:
            response = await client.get(url, timeout=30)
        
        response.raise_for_status()
        data = response.json()
        
        score_zero = data.get('score_zero', 0)
        # "score is not 0" technically includes existing scores != 0. 
        # Depending on your definition, you might want to include or exclude NULLs.
        # The DB query separates NULLs, so 'score_not_zero' implies analyzed positions that aren't draws.
        score_not_zero = data.get('score_not_zero', 0)
        score_null = data.get('score_null', 0)

        print("\n--- SUCCESS (FEN Score Counts) ---")
        print(f"Player: {player_name}")
        print(f"├── Score == 0 (Draw/Equal):  {score_zero:,}")
        print(f"├── Score != 0 (Decisive):    {score_not_zero:,}")
        print(f"└── Score is NULL (Unscored): {score_null:,}")
        print(f"Total FENs associated: {score_zero + score_not_zero + score_null:,}")
        
        return score_zero, score_not_zero

    except httpx.HTTPStatusError as e:
        print(f"\n--- ERROR (HTTP {e.response.status_code}) ---")
        print(e.response.text)
        return 0, 0
    except Exception as e:
        print(f"\n--- UNEXPECTED ERROR ---")
        print(repr(e))
        return 0, 0



### worker.py 
# worker.py
import os
import constants
from arq.connections import RedisSettings
from arq import create_pool 

# --- Import the actual job functions from your operations ---
# These are the tasks the worker is allowed to run.
from chessism_api.operations.analysis import (
    run_analysis_job, 
    run_player_analysis_job
)
# --- MODIFIED: Import BOTH FEN jobs ---
from chessism_api.operations.fens import (
    run_fen_generation_job,
    run_fen_pipeline
)

# --- NEW: Import the database initializer ---
from chessism_api.database.engine import init_db
# --- NEW: Import Redis client for the boss job ---
from chessism_api.redis_client import redis_settings


# --- NEW: Read queue name from environment ---
# This allows docker-compose to assign different queues to different workers
WORKER_QUEUE = os.environ.get("QUEUE_NAME", "default")
print(f"--- [WORKER] Starting up, listening on queue: {WORKER_QUEUE} ---", flush=True)


# --- NEW: Worker startup function ---
async def startup(ctx):
    """
    This function is run by arq when the worker starts.
    It initializes the database connection for this process.
    """
    print(f"--- [WORKER] Initializing database connection... ---", flush=True)
    if not constants.CONN_STRING:
        raise ValueError("DATABASE_URL environment variable is not set for worker.")
    await init_db(constants.CONN_STRING)
    print(f"--- [WORKER] Database connection initialized. ---", flush=True)
    
    # --- NEW: Add a redis pool to the 'boss' worker's context ---
    # This allows run_fen_pipeline to enqueue jobs
    ctx['redis'] = await create_pool(redis_settings)


# --- NEW: Worker shutdown function ---
async def shutdown(ctx):
    """
    Closes the redis pool on shutdown.
    """
    print(f"--- [WORKER] Shutting down... ---", flush=True)
    redis = ctx.get('redis')
    if redis:
        await redis.close()
    print(f"--- [WORKER] Shutdown complete. ---", flush=True)


# --- This is the main configuration class for ARQ ---
class WorkerSettings:
    """
    Defines the worker's settings.
    ARQ reads this class to know what functions to listen for
    and where to connect.
    """
    
    # --- MODIFIED: Added the "boss" pipeline job ---
    functions = [
        run_analysis_job, 
        run_player_analysis_job,
        run_fen_generation_job,
        run_fen_pipeline
    ]
    
    redis_settings = redis_settings
    
    # --- MODIFIED: Use the dynamic queue name ---
    queue_name = WORKER_QUEUE

    # --- NEW: Tell arq to run the startup/shutdown functions ---
    on_startup = startup
    on_shutdown = shutdown

    # --- Force the worker to run only one job at a time ---
    max_jobs = 1

    # --- Set the worker's global timeout to 24 hours ---
    job_timeout = 86400

