
            Part six: utilities
            This is the sixth part, it contains bash scripts for backup the database, restore the database,
            and record the temperature of the nvidia cards
            


### backup.sh 
#!/bin/bash

# This script creates a compressed backup of your PostgreSQL database.
# It uses 'docker-compose exec' to run pg_dump inside the running 'db' container.
# --- MODIFIED: This script will now delete the single most recent backup in
#          the target directory before creating a new one. ---

# --- Stop script on any error ---
set -e

# --- Configuration ---
# Get these values from your docker-compose.yml
CONTAINER_NAME="db"
DB_USER="chessism_user"
DB_NAME="chessism_db"
OUTPUT_DIR="./backups" # We will create this directory

# --- Create backup directory if it doesn't exist ---
mkdir -p $OUTPUT_DIR

# --- NEW: Find and delete the most recent backup ---
echo "Checking for previous backup..."
# Find the newest file in the directory matching the pattern
# ls -t lists by modification time, newest first
# head -n 1 takes only the first line
# 2>/dev/null hides the "No such file or directory" error if no backups exist
LATEST_BACKUP=$(ls -t "$OUTPUT_DIR"/backup-"$DB_NAME"-*.dump 2>/dev/null | head -n 1)

if [ -f "$LATEST_BACKUP" ]; then
    echo "Found previous backup: $LATEST_BACKUP"
    echo "Deleting it..."
    rm "$LATEST_BACKUP"
    echo "Previous backup deleted."
else
    echo "No previous backups found."
fi
# --- END NEW SECTION ---


# --- Backup Filename ---
# Creates a filename like: backup-chessism_db-2025_11_10-22_15_30.dump
FILENAME="backup-${DB_NAME}-$(date +%Y_%m_%d-%H_%M_%S).dump"
FULL_PATH="$OUTPUT_DIR/$FILENAME"

echo "Starting new backup of database '$DB_NAME'..."

# --- The Backup Command ---
# docker-compose exec [service_name] [command_to_run]
#
# -T               : Disables pseudo-tty allocation (necessary for redirecting output)
# pg_dump          : The PostgreSQL backup utility
# -U $DB_USER    : The username to connect as
# -d $DB_NAME    : The database to dump
# -F c             : Format = Custom (compressed, efficient format)
# > $FULL_PATH   : Redirects the output from the command to a file on your host machine
docker-compose exec -T $CONTAINER_NAME pg_dump -U $DB_USER -d $DB_NAME -F c > $FULL_PATH

# --- Success Message ---
echo ""
echo "✅ New backup complete!"
echo "File created at: $FULL_PATH"



### restore_db_from_backup.sh 
#!/bin/bash

# --- Stop script on any error ---
set -e

# --- Configuration ---
CONTAINER_NAME="db"
DB_USER="chessism_user"
DB_NAME="chessism_db"
BACKUP_DIR="./backups"
BACKUP_PATTERN="$BACKUP_DIR/backup-${DB_NAME}-*.dump"

echo "Starting database restoration for '$DB_NAME'..."

# --- 1. Find the latest backup file ---
# ls -t lists by modification time, newest first. head -n 1 takes the newest file.
LATEST_BACKUP=$(ls -t $BACKUP_PATTERN 2>/dev/null | head -n 1)

if [ -z "$LATEST_BACKUP" ]; then
    echo "❌ Error: No backup files found matching pattern '$BACKUP_PATTERN'."
    exit 1
fi

echo "Found latest backup file: $(basename $LATEST_BACKUP)"
echo "Restoring database from $LATEST_BACKUP..."

# --- 2. Check if containers are running ---
# Check if the target container is running (returns non-zero if not running)
if ! docker compose ps -q $CONTAINER_NAME | grep -q .; then
    echo "❌ Error: Docker service '$CONTAINER_NAME' is not running. Please run 'docker compose up -d' first."
    exit 1
fi

# --- 3. Execute the Restore Command ---
# cat [file] | pipes the file content into the pg_restore command inside the container.
# --clean: drops existing tables before restoring them.
cat "$LATEST_BACKUP" | docker compose exec -T $CONTAINER_NAME pg_restore -U $DB_USER -d $DB_NAME --clean

# --- 4. Success Message ---
echo ""
echo "✅ Restoration complete! The database '$DB_NAME' is now restored."



### start_temp_monitor.sh 
#!/bin/bash

# This script starts a background monitor for your NVIDIA GPUs.
# It logs the timestamp, index, name, temperature, utilization, and clock speed
# to a CSV file every 60 seconds.

LOG_FILE="gpu_temp_log.csv"
POLL_INTERVAL_SECONDS=60

echo "Starting GPU monitor..."
echo "Logging to: $LOG_FILE"
echo "Polling every: $POLL_INTERVAL_SECONDS seconds"

# Check if the log file is new. If it is, add a header row.
if [ ! -f "$LOG_FILE" ]; then
    echo "Creating new log file with headers."
    # This first command runs once to create the file and add the CSV header
    nvidia-smi \
        --query-gpu=timestamp,index,name,temperature.gpu,utilization.gpu,clocks.gr \
        --format=csv,noheader,nounits \
        > $LOG_FILE
fi

# 'nohup' ensures the command keeps running even if you close your terminal.
# '>>' appends to the file.
# '&' runs the command in the background.
nohup nvidia-smi \
    --query-gpu=timestamp,index,name,temperature.gpu,utilization.gpu,clocks.gr \
    --format=csv,noheader,nounits \
    --loop=$POLL_INTERVAL_SECONDS \
    >> $LOG_FILE &

# Get the Process ID (PID) of the background job
MONITOR_PID=$!

echo "Monitor started in background with PID: $MONITOR_PID"
echo "You can now close this terminal. The log will be saved to $LOG_FILE"
echo "----------------------------------------------------------------"
echo "To watch the log in real-time, run:"
echo "tail -f $LOG_FILE"
echo ""
echo "To stop the monitor later, run:"
echo "kill $MONITOR_PID"
echo "(If you lose the PID, run 'pkill -f \"nvidia-smi --loop\"')"

